2023-10-25 12:44:41,597:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-25 12:44:41,599:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-25 12:44:41,599:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-25 12:44:41,599:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-25 12:45:16,491:INFO:PyCaret ClassificationExperiment
2023-10-25 12:45:16,492:INFO:Logging name: pycaret_1
2023-10-25 12:45:16,492:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-10-25 12:45:16,492:INFO:version 3.1.0
2023-10-25 12:45:16,492:INFO:Initializing setup()
2023-10-25 12:45:16,494:INFO:self.USI: d391
2023-10-25 12:45:16,494:INFO:self._variable_keys: {'pipeline', 'fold_generator', 'n_jobs_param', 'memory', 'gpu_param', 'y_train', 'X_test', 'data', 'fix_imbalance', 'is_multiclass', 'fold_shuffle_param', 'X', 'html_param', 'y_test', 'exp_id', 'gpu_n_jobs_param', 'X_train', 'y', 'logging_param', 'target_param', 'USI', 'exp_name_log', 'log_plots_param', '_ml_usecase', 'idx', '_available_plots', 'fold_groups_param', 'seed'}
2023-10-25 12:45:16,494:INFO:Checking environment
2023-10-25 12:45:16,495:INFO:python_version: 3.8.18
2023-10-25 12:45:16,495:INFO:python_build: ('default', 'Sep 11 2023 13:39:12')
2023-10-25 12:45:16,496:INFO:machine: AMD64
2023-10-25 12:45:16,496:INFO:platform: Windows-10-10.0.22621-SP0
2023-10-25 12:45:16,497:INFO:Memory: svmem(total=16883044352, available=2966781952, percent=82.4, used=13916262400, free=2966781952)
2023-10-25 12:45:16,498:INFO:Physical Core: 4
2023-10-25 12:45:16,498:INFO:Logical Core: 8
2023-10-25 12:45:16,498:INFO:Checking libraries
2023-10-25 12:45:16,498:INFO:System:
2023-10-25 12:45:16,498:INFO:    python: 3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]
2023-10-25 12:45:16,498:INFO:executable: c:\Users\enric\.conda\envs\npl-tweets\python.exe
2023-10-25 12:45:16,499:INFO:   machine: Windows-10-10.0.22621-SP0
2023-10-25 12:45:16,499:INFO:PyCaret required dependencies:
2023-10-25 12:45:16,553:INFO:                 pip: 23.3
2023-10-25 12:45:16,554:INFO:          setuptools: 68.0.0
2023-10-25 12:45:16,554:INFO:             pycaret: 3.1.0
2023-10-25 12:45:16,554:INFO:             IPython: 8.12.2
2023-10-25 12:45:16,554:INFO:          ipywidgets: 8.1.1
2023-10-25 12:45:16,554:INFO:                tqdm: 4.65.0
2023-10-25 12:45:16,554:INFO:               numpy: 1.23.5
2023-10-25 12:45:16,555:INFO:              pandas: 1.5.3
2023-10-25 12:45:16,555:INFO:              jinja2: 3.1.2
2023-10-25 12:45:16,555:INFO:               scipy: 1.10.1
2023-10-25 12:45:16,555:INFO:              joblib: 1.2.0
2023-10-25 12:45:16,555:INFO:             sklearn: 1.2.2
2023-10-25 12:45:16,555:INFO:                pyod: 1.1.1
2023-10-25 12:45:16,555:INFO:            imblearn: 0.11.0
2023-10-25 12:45:16,555:INFO:   category_encoders: 2.6.2
2023-10-25 12:45:16,555:INFO:            lightgbm: 4.1.0
2023-10-25 12:45:16,555:INFO:               numba: 0.58.1
2023-10-25 12:45:16,555:INFO:            requests: 2.31.0
2023-10-25 12:45:16,555:INFO:          matplotlib: 3.7.2
2023-10-25 12:45:16,556:INFO:          scikitplot: 0.3.7
2023-10-25 12:45:16,556:INFO:         yellowbrick: 1.5
2023-10-25 12:45:16,556:INFO:              plotly: 5.17.0
2023-10-25 12:45:16,556:INFO:    plotly-resampler: Not installed
2023-10-25 12:45:16,556:INFO:             kaleido: 0.2.1
2023-10-25 12:45:16,556:INFO:           schemdraw: 0.15
2023-10-25 12:45:16,557:INFO:         statsmodels: 0.14.0
2023-10-25 12:45:16,557:INFO:              sktime: 0.21.1
2023-10-25 12:45:16,557:INFO:               tbats: 1.1.3
2023-10-25 12:45:16,557:INFO:            pmdarima: 2.0.4
2023-10-25 12:45:16,557:INFO:              psutil: 5.9.0
2023-10-25 12:45:16,557:INFO:          markupsafe: 2.1.1
2023-10-25 12:45:16,557:INFO:             pickle5: Not installed
2023-10-25 12:45:16,557:INFO:         cloudpickle: 2.2.1
2023-10-25 12:45:16,558:INFO:         deprecation: 2.1.0
2023-10-25 12:45:16,558:INFO:              xxhash: 3.4.1
2023-10-25 12:45:16,559:INFO:           wurlitzer: Not installed
2023-10-25 12:45:16,559:INFO:PyCaret optional dependencies:
2023-10-25 12:45:16,609:INFO:                shap: Not installed
2023-10-25 12:45:16,609:INFO:           interpret: Not installed
2023-10-25 12:45:16,609:INFO:                umap: Not installed
2023-10-25 12:45:16,609:INFO:     ydata_profiling: Not installed
2023-10-25 12:45:16,609:INFO:  explainerdashboard: Not installed
2023-10-25 12:45:16,609:INFO:             autoviz: Not installed
2023-10-25 12:45:16,609:INFO:           fairlearn: Not installed
2023-10-25 12:45:16,609:INFO:          deepchecks: Not installed
2023-10-25 12:45:16,611:INFO:             xgboost: Not installed
2023-10-25 12:45:16,611:INFO:            catboost: Not installed
2023-10-25 12:45:16,611:INFO:              kmodes: Not installed
2023-10-25 12:45:16,611:INFO:             mlxtend: Not installed
2023-10-25 12:45:16,611:INFO:       statsforecast: Not installed
2023-10-25 12:45:16,611:INFO:        tune_sklearn: Not installed
2023-10-25 12:45:16,611:INFO:                 ray: Not installed
2023-10-25 12:45:16,611:INFO:            hyperopt: Not installed
2023-10-25 12:45:16,611:INFO:              optuna: Not installed
2023-10-25 12:45:16,611:INFO:               skopt: Not installed
2023-10-25 12:45:16,612:INFO:              mlflow: 2.6.0
2023-10-25 12:45:16,612:INFO:              gradio: Not installed
2023-10-25 12:45:16,612:INFO:             fastapi: Not installed
2023-10-25 12:45:16,612:INFO:             uvicorn: Not installed
2023-10-25 12:45:16,612:INFO:              m2cgen: Not installed
2023-10-25 12:45:16,612:INFO:           evidently: Not installed
2023-10-25 12:45:16,612:INFO:               fugue: Not installed
2023-10-25 12:45:16,612:INFO:           streamlit: Not installed
2023-10-25 12:45:16,613:INFO:             prophet: Not installed
2023-10-25 12:45:16,613:INFO:None
2023-10-25 12:45:16,613:INFO:Set up data.
2023-10-25 12:45:39,103:INFO:Set up folding strategy.
2023-10-25 12:45:39,104:INFO:Set up train/test split.
2023-10-25 12:45:44,161:INFO:Set up index.
2023-10-25 12:45:44,301:INFO:Assigning column types.
2023-10-25 12:45:47,986:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-25 12:45:48,167:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-25 12:45:48,184:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-10-25 12:45:48,363:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-25 12:45:48,364:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-25 12:45:48,504:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-25 12:45:48,510:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-10-25 12:45:48,592:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-25 12:45:48,592:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-25 12:45:48,594:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-25 12:45:48,750:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-10-25 12:45:48,826:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-25 12:45:48,828:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-25 12:45:48,935:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-10-25 12:45:49,005:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-25 12:45:49,006:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-25 12:45:49,006:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-10-25 12:45:49,215:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-25 12:45:49,216:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-25 12:45:49,420:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-25 12:45:49,420:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-25 12:45:52,276:INFO:Finished creating preprocessing pipeline.
2023-10-25 12:45:52,282:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\enric\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False)
2023-10-25 12:45:52,282:INFO:Creating final display dataframe.
2023-10-25 12:46:02,356:INFO:Setup _display_container:                    Description          Value
0                   Session id            123
1                       Target         target
2                  Target type         Binary
3          Original data shape  (7613, 17683)
4       Transformed data shape  (7613, 17683)
5  Transformed train set shape  (5329, 17683)
6   Transformed test set shape  (2284, 17683)
7             Numeric features          17682
2023-10-25 12:46:02,522:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-25 12:46:02,523:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-25 12:46:02,660:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-25 12:46:02,660:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-25 12:46:02,661:INFO:Logging experiment in loggers
2023-10-25 12:46:03,517:INFO:SubProcess save_model() called ==================================
2023-10-25 12:46:03,520:INFO:Initializing save_model()
2023-10-25 12:46:03,520:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\enric\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False), model_name=C:\Users\enric\AppData\Local\Temp\tmpi5_nww3o\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\enric\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-10-25 12:46:03,520:INFO:Adding model into prep_pipe
2023-10-25 12:46:03,522:WARNING:Only Model saved as it was a pipeline.
2023-10-25 12:46:03,824:INFO:C:\Users\enric\AppData\Local\Temp\tmpi5_nww3o\Transformation Pipeline.pkl saved in current working directory
2023-10-25 12:46:03,826:INFO:Pipeline(memory=FastMemory(location=C:\Users\enric\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False)
2023-10-25 12:46:03,828:INFO:save_model() successfully completed......................................
2023-10-25 12:46:04,159:INFO:SubProcess save_model() end ==================================
2023-10-25 12:46:04,213:INFO:setup() successfully completed in 46.18s...............
2023-10-25 12:46:04,270:INFO:Initializing compare_models()
2023-10-25 12:46:04,271:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BDB7F9B9A0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002BDB7F9B9A0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-10-25 12:46:04,272:INFO:Checking exceptions
2023-10-25 12:46:06,385:INFO:Preparing display monitor
2023-10-25 12:46:06,454:INFO:Initializing Logistic Regression
2023-10-25 12:46:06,455:INFO:Total runtime is 1.662572224934896e-05 minutes
2023-10-25 12:46:06,468:INFO:SubProcess create_model() called ==================================
2023-10-25 12:46:06,468:INFO:Initializing create_model()
2023-10-25 12:46:06,469:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BDB7F9B9A0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002BDB7F66C70>, model_only=True, return_train_score=False, kwargs={})
2023-10-25 12:46:06,469:INFO:Checking exceptions
2023-10-25 12:46:06,470:INFO:Importing libraries
2023-10-25 12:46:06,470:INFO:Copying training dataset
2023-10-25 12:46:09,510:INFO:Defining folds
2023-10-25 12:46:09,512:INFO:Declaring metric variables
2023-10-25 12:46:09,523:INFO:Importing untrained model
2023-10-25 12:46:09,538:INFO:Logistic Regression Imported successfully
2023-10-25 12:46:09,608:INFO:Starting cross validation
2023-10-25 12:46:09,682:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-25 12:48:15,039:INFO:Calculating mean and std
2023-10-25 12:48:15,042:INFO:Creating metrics dataframe
2023-10-25 12:48:15,052:INFO:Uploading results into container
2023-10-25 12:48:15,055:INFO:Uploading model into container now
2023-10-25 12:48:15,056:INFO:_master_model_container: 1
2023-10-25 12:48:15,057:INFO:_display_container: 2
2023-10-25 12:48:15,060:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-10-25 12:48:15,061:INFO:create_model() successfully completed......................................
2023-10-25 12:48:15,346:INFO:SubProcess create_model() end ==================================
2023-10-25 12:48:15,346:INFO:Creating metrics dataframe
2023-10-25 12:48:15,374:INFO:Initializing K Neighbors Classifier
2023-10-25 12:48:15,374:INFO:Total runtime is 2.148671865463257 minutes
2023-10-25 12:48:15,383:INFO:SubProcess create_model() called ==================================
2023-10-25 12:48:15,383:INFO:Initializing create_model()
2023-10-25 12:48:15,383:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BDB7F9B9A0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002BDB7F66C70>, model_only=True, return_train_score=False, kwargs={})
2023-10-25 12:48:15,384:INFO:Checking exceptions
2023-10-25 12:48:15,384:INFO:Importing libraries
2023-10-25 12:48:15,384:INFO:Copying training dataset
2023-10-25 12:48:18,224:INFO:Defining folds
2023-10-25 12:48:18,224:INFO:Declaring metric variables
2023-10-25 12:48:18,239:INFO:Importing untrained model
2023-10-25 12:48:18,249:INFO:K Neighbors Classifier Imported successfully
2023-10-25 12:48:18,254:INFO:Starting cross validation
2023-10-25 12:48:18,274:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-25 12:48:28,142:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_classification.py", line 283, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_base.py", line 824, in kneighbors
    results = ArgKmin.compute(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 289, in compute
    return ArgKmin32.compute(
  File "sklearn\metrics\_pairwise_distances_reduction\_argkmin.pyx", line 584, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\fixes.py", line 139, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 373, in _load_modules
    self._find_modules_with_enum_process_module_ex()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 485, in _find_modules_with_enum_process_module_ex
    self._make_module_from_path(filepath)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 646, in get_version
    config = get_config().split()
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2023-10-25 12:48:28,189:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_classification.py", line 283, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_base.py", line 824, in kneighbors
    results = ArgKmin.compute(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 289, in compute
    return ArgKmin32.compute(
  File "sklearn\metrics\_pairwise_distances_reduction\_argkmin.pyx", line 584, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\fixes.py", line 139, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 373, in _load_modules
    self._find_modules_with_enum_process_module_ex()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 485, in _find_modules_with_enum_process_module_ex
    self._make_module_from_path(filepath)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 646, in get_version
    config = get_config().split()
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2023-10-25 12:48:28,205:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_classification.py", line 283, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_base.py", line 824, in kneighbors
    results = ArgKmin.compute(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 289, in compute
    return ArgKmin32.compute(
  File "sklearn\metrics\_pairwise_distances_reduction\_argkmin.pyx", line 584, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\fixes.py", line 139, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 373, in _load_modules
    self._find_modules_with_enum_process_module_ex()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 485, in _find_modules_with_enum_process_module_ex
    self._make_module_from_path(filepath)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 646, in get_version
    config = get_config().split()
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2023-10-25 12:48:28,568:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_classification.py", line 283, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_base.py", line 824, in kneighbors
    results = ArgKmin.compute(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 289, in compute
    return ArgKmin32.compute(
  File "sklearn\metrics\_pairwise_distances_reduction\_argkmin.pyx", line 584, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\fixes.py", line 139, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 373, in _load_modules
    self._find_modules_with_enum_process_module_ex()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 485, in _find_modules_with_enum_process_module_ex
    self._make_module_from_path(filepath)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 646, in get_version
    config = get_config().split()
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2023-10-25 12:48:28,857:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_classification.py", line 283, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_base.py", line 824, in kneighbors
    results = ArgKmin.compute(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 289, in compute
    return ArgKmin32.compute(
  File "sklearn\metrics\_pairwise_distances_reduction\_argkmin.pyx", line 584, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\fixes.py", line 139, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 373, in _load_modules
    self._find_modules_with_enum_process_module_ex()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 485, in _find_modules_with_enum_process_module_ex
    self._make_module_from_path(filepath)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 646, in get_version
    config = get_config().split()
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2023-10-25 12:48:29,156:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_classification.py", line 283, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_base.py", line 824, in kneighbors
    results = ArgKmin.compute(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 289, in compute
    return ArgKmin32.compute(
  File "sklearn\metrics\_pairwise_distances_reduction\_argkmin.pyx", line 584, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\fixes.py", line 139, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 373, in _load_modules
    self._find_modules_with_enum_process_module_ex()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 485, in _find_modules_with_enum_process_module_ex
    self._make_module_from_path(filepath)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 646, in get_version
    config = get_config().split()
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2023-10-25 12:48:29,381:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_classification.py", line 283, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_base.py", line 824, in kneighbors
    results = ArgKmin.compute(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 289, in compute
    return ArgKmin32.compute(
  File "sklearn\metrics\_pairwise_distances_reduction\_argkmin.pyx", line 584, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\fixes.py", line 139, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 373, in _load_modules
    self._find_modules_with_enum_process_module_ex()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 485, in _find_modules_with_enum_process_module_ex
    self._make_module_from_path(filepath)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 646, in get_version
    config = get_config().split()
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2023-10-25 12:48:29,420:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_classification.py", line 283, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_base.py", line 824, in kneighbors
    results = ArgKmin.compute(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 289, in compute
    return ArgKmin32.compute(
  File "sklearn\metrics\_pairwise_distances_reduction\_argkmin.pyx", line 584, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\fixes.py", line 139, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 373, in _load_modules
    self._find_modules_with_enum_process_module_ex()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 485, in _find_modules_with_enum_process_module_ex
    self._make_module_from_path(filepath)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 646, in get_version
    config = get_config().split()
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2023-10-25 12:48:32,567:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 276, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_classification.py", line 234, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_base.py", line 824, in kneighbors
    results = ArgKmin.compute(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 289, in compute
    return ArgKmin32.compute(
  File "sklearn\metrics\_pairwise_distances_reduction\_argkmin.pyx", line 584, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\fixes.py", line 139, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 373, in _load_modules
    self._find_modules_with_enum_process_module_ex()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 485, in _find_modules_with_enum_process_module_ex
    self._make_module_from_path(filepath)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 646, in get_version
    config = get_config().split()
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2023-10-25 12:48:33,010:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 276, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_classification.py", line 234, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_base.py", line 824, in kneighbors
    results = ArgKmin.compute(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 289, in compute
    return ArgKmin32.compute(
  File "sklearn\metrics\_pairwise_distances_reduction\_argkmin.pyx", line 584, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\fixes.py", line 139, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 373, in _load_modules
    self._find_modules_with_enum_process_module_ex()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 485, in _find_modules_with_enum_process_module_ex
    self._make_module_from_path(filepath)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 646, in get_version
    config = get_config().split()
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2023-10-25 12:48:33,027:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 276, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_classification.py", line 234, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_base.py", line 824, in kneighbors
    results = ArgKmin.compute(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 289, in compute
    return ArgKmin32.compute(
  File "sklearn\metrics\_pairwise_distances_reduction\_argkmin.pyx", line 584, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\fixes.py", line 139, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 373, in _load_modules
    self._find_modules_with_enum_process_module_ex()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 485, in _find_modules_with_enum_process_module_ex
    self._make_module_from_path(filepath)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 646, in get_version
    config = get_config().split()
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2023-10-25 12:48:33,157:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 276, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_classification.py", line 234, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_base.py", line 824, in kneighbors
    results = ArgKmin.compute(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 289, in compute
    return ArgKmin32.compute(
  File "sklearn\metrics\_pairwise_distances_reduction\_argkmin.pyx", line 584, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\fixes.py", line 139, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 373, in _load_modules
    self._find_modules_with_enum_process_module_ex()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 485, in _find_modules_with_enum_process_module_ex
    self._make_module_from_path(filepath)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 646, in get_version
    config = get_config().split()
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2023-10-25 12:48:33,356:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 276, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_classification.py", line 234, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_base.py", line 824, in kneighbors
    results = ArgKmin.compute(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 289, in compute
    return ArgKmin32.compute(
  File "sklearn\metrics\_pairwise_distances_reduction\_argkmin.pyx", line 584, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\fixes.py", line 139, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 373, in _load_modules
    self._find_modules_with_enum_process_module_ex()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 485, in _find_modules_with_enum_process_module_ex
    self._make_module_from_path(filepath)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 646, in get_version
    config = get_config().split()
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2023-10-25 12:48:33,392:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 276, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_classification.py", line 234, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_base.py", line 824, in kneighbors
    results = ArgKmin.compute(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 289, in compute
    return ArgKmin32.compute(
  File "sklearn\metrics\_pairwise_distances_reduction\_argkmin.pyx", line 584, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\fixes.py", line 139, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 373, in _load_modules
    self._find_modules_with_enum_process_module_ex()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 485, in _find_modules_with_enum_process_module_ex
    self._make_module_from_path(filepath)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 646, in get_version
    config = get_config().split()
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2023-10-25 12:48:34,192:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 276, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_classification.py", line 234, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_base.py", line 824, in kneighbors
    results = ArgKmin.compute(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 289, in compute
    return ArgKmin32.compute(
  File "sklearn\metrics\_pairwise_distances_reduction\_argkmin.pyx", line 584, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\fixes.py", line 139, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 373, in _load_modules
    self._find_modules_with_enum_process_module_ex()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 485, in _find_modules_with_enum_process_module_ex
    self._make_module_from_path(filepath)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 646, in get_version
    config = get_config().split()
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2023-10-25 12:48:34,334:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 276, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_classification.py", line 234, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_base.py", line 824, in kneighbors
    results = ArgKmin.compute(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 289, in compute
    return ArgKmin32.compute(
  File "sklearn\metrics\_pairwise_distances_reduction\_argkmin.pyx", line 584, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\fixes.py", line 139, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 373, in _load_modules
    self._find_modules_with_enum_process_module_ex()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 485, in _find_modules_with_enum_process_module_ex
    self._make_module_from_path(filepath)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 646, in get_version
    config = get_config().split()
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2023-10-25 12:48:37,654:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_classification.py", line 283, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_base.py", line 824, in kneighbors
    results = ArgKmin.compute(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 289, in compute
    return ArgKmin32.compute(
  File "sklearn\metrics\_pairwise_distances_reduction\_argkmin.pyx", line 584, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\fixes.py", line 139, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 373, in _load_modules
    self._find_modules_with_enum_process_module_ex()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 485, in _find_modules_with_enum_process_module_ex
    self._make_module_from_path(filepath)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 646, in get_version
    config = get_config().split()
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2023-10-25 12:48:37,700:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_classification.py", line 283, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_base.py", line 824, in kneighbors
    results = ArgKmin.compute(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 289, in compute
    return ArgKmin32.compute(
  File "sklearn\metrics\_pairwise_distances_reduction\_argkmin.pyx", line 584, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\fixes.py", line 139, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 373, in _load_modules
    self._find_modules_with_enum_process_module_ex()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 485, in _find_modules_with_enum_process_module_ex
    self._make_module_from_path(filepath)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 646, in get_version
    config = get_config().split()
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2023-10-25 12:48:40,031:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 276, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_classification.py", line 234, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_base.py", line 824, in kneighbors
    results = ArgKmin.compute(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 289, in compute
    return ArgKmin32.compute(
  File "sklearn\metrics\_pairwise_distances_reduction\_argkmin.pyx", line 584, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\fixes.py", line 139, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 373, in _load_modules
    self._find_modules_with_enum_process_module_ex()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 485, in _find_modules_with_enum_process_module_ex
    self._make_module_from_path(filepath)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 646, in get_version
    config = get_config().split()
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2023-10-25 12:48:40,063:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 276, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_classification.py", line 234, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_base.py", line 824, in kneighbors
    results = ArgKmin.compute(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 289, in compute
    return ArgKmin32.compute(
  File "sklearn\metrics\_pairwise_distances_reduction\_argkmin.pyx", line 584, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\fixes.py", line 139, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 373, in _load_modules
    self._find_modules_with_enum_process_module_ex()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 485, in _find_modules_with_enum_process_module_ex
    self._make_module_from_path(filepath)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 646, in get_version
    config = get_config().split()
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2023-10-25 12:48:40,385:INFO:Calculating mean and std
2023-10-25 12:48:40,385:INFO:Creating metrics dataframe
2023-10-25 12:48:40,401:INFO:Uploading results into container
2023-10-25 12:48:40,401:INFO:Uploading model into container now
2023-10-25 12:48:40,401:INFO:_master_model_container: 2
2023-10-25 12:48:40,401:INFO:_display_container: 2
2023-10-25 12:48:40,401:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-10-25 12:48:40,401:INFO:create_model() successfully completed......................................
2023-10-25 12:48:40,591:WARNING:create_model() for KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform') raised an exception or returned all 0.0, trying without fit_kwargs:
2023-10-25 12:48:40,607:WARNING:Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 798, in compare_models
    assert (
AssertionError

2023-10-25 12:48:40,607:INFO:Initializing create_model()
2023-10-25 12:48:40,607:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BDB7F9B9A0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002BDB7F66C70>, model_only=True, return_train_score=False, kwargs={})
2023-10-25 12:48:40,607:INFO:Checking exceptions
2023-10-25 12:48:40,607:INFO:Importing libraries
2023-10-25 12:48:40,607:INFO:Copying training dataset
2023-10-25 12:48:42,357:INFO:Defining folds
2023-10-25 12:48:42,357:INFO:Declaring metric variables
2023-10-25 12:48:42,365:INFO:Importing untrained model
2023-10-25 12:48:42,372:INFO:K Neighbors Classifier Imported successfully
2023-10-25 12:48:42,388:INFO:Starting cross validation
2023-10-25 12:48:42,412:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-25 12:48:55,615:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_classification.py", line 283, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_base.py", line 824, in kneighbors
    results = ArgKmin.compute(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 289, in compute
    return ArgKmin32.compute(
  File "sklearn\metrics\_pairwise_distances_reduction\_argkmin.pyx", line 584, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\fixes.py", line 139, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 373, in _load_modules
    self._find_modules_with_enum_process_module_ex()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 485, in _find_modules_with_enum_process_module_ex
    self._make_module_from_path(filepath)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 646, in get_version
    config = get_config().split()
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2023-10-25 12:48:55,756:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_classification.py", line 283, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_base.py", line 824, in kneighbors
    results = ArgKmin.compute(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 289, in compute
    return ArgKmin32.compute(
  File "sklearn\metrics\_pairwise_distances_reduction\_argkmin.pyx", line 584, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\fixes.py", line 139, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 373, in _load_modules
    self._find_modules_with_enum_process_module_ex()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 485, in _find_modules_with_enum_process_module_ex
    self._make_module_from_path(filepath)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 646, in get_version
    config = get_config().split()
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2023-10-25 12:48:55,772:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_classification.py", line 283, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_base.py", line 824, in kneighbors
    results = ArgKmin.compute(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 289, in compute
    return ArgKmin32.compute(
  File "sklearn\metrics\_pairwise_distances_reduction\_argkmin.pyx", line 584, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\fixes.py", line 139, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 373, in _load_modules
    self._find_modules_with_enum_process_module_ex()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 485, in _find_modules_with_enum_process_module_ex
    self._make_module_from_path(filepath)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 646, in get_version
    config = get_config().split()
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2023-10-25 12:48:55,772:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_classification.py", line 283, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_base.py", line 824, in kneighbors
    results = ArgKmin.compute(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 289, in compute
    return ArgKmin32.compute(
  File "sklearn\metrics\_pairwise_distances_reduction\_argkmin.pyx", line 584, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\fixes.py", line 139, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 373, in _load_modules
    self._find_modules_with_enum_process_module_ex()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 485, in _find_modules_with_enum_process_module_ex
    self._make_module_from_path(filepath)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 646, in get_version
    config = get_config().split()
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2023-10-25 12:48:56,326:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_classification.py", line 283, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_base.py", line 824, in kneighbors
    results = ArgKmin.compute(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 289, in compute
    return ArgKmin32.compute(
  File "sklearn\metrics\_pairwise_distances_reduction\_argkmin.pyx", line 584, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\fixes.py", line 139, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 373, in _load_modules
    self._find_modules_with_enum_process_module_ex()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 485, in _find_modules_with_enum_process_module_ex
    self._make_module_from_path(filepath)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 646, in get_version
    config = get_config().split()
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2023-10-25 12:48:56,343:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_classification.py", line 283, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_base.py", line 824, in kneighbors
    results = ArgKmin.compute(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 289, in compute
    return ArgKmin32.compute(
  File "sklearn\metrics\_pairwise_distances_reduction\_argkmin.pyx", line 584, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\fixes.py", line 139, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 373, in _load_modules
    self._find_modules_with_enum_process_module_ex()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 485, in _find_modules_with_enum_process_module_ex
    self._make_module_from_path(filepath)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 646, in get_version
    config = get_config().split()
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2023-10-25 12:48:56,365:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_classification.py", line 283, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_base.py", line 824, in kneighbors
    results = ArgKmin.compute(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 289, in compute
    return ArgKmin32.compute(
  File "sklearn\metrics\_pairwise_distances_reduction\_argkmin.pyx", line 584, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\fixes.py", line 139, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 373, in _load_modules
    self._find_modules_with_enum_process_module_ex()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 485, in _find_modules_with_enum_process_module_ex
    self._make_module_from_path(filepath)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 646, in get_version
    config = get_config().split()
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2023-10-25 12:48:56,420:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_classification.py", line 283, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_base.py", line 824, in kneighbors
    results = ArgKmin.compute(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 289, in compute
    return ArgKmin32.compute(
  File "sklearn\metrics\_pairwise_distances_reduction\_argkmin.pyx", line 584, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\fixes.py", line 139, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 373, in _load_modules
    self._find_modules_with_enum_process_module_ex()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 485, in _find_modules_with_enum_process_module_ex
    self._make_module_from_path(filepath)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 646, in get_version
    config = get_config().split()
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2023-10-25 12:48:59,931:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 276, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_classification.py", line 234, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_base.py", line 824, in kneighbors
    results = ArgKmin.compute(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 289, in compute
    return ArgKmin32.compute(
  File "sklearn\metrics\_pairwise_distances_reduction\_argkmin.pyx", line 584, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\fixes.py", line 139, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 373, in _load_modules
    self._find_modules_with_enum_process_module_ex()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 485, in _find_modules_with_enum_process_module_ex
    self._make_module_from_path(filepath)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 646, in get_version
    config = get_config().split()
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2023-10-25 12:49:00,635:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 276, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_classification.py", line 234, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_base.py", line 824, in kneighbors
    results = ArgKmin.compute(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 289, in compute
    return ArgKmin32.compute(
  File "sklearn\metrics\_pairwise_distances_reduction\_argkmin.pyx", line 584, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\fixes.py", line 139, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 373, in _load_modules
    self._find_modules_with_enum_process_module_ex()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 485, in _find_modules_with_enum_process_module_ex
    self._make_module_from_path(filepath)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 646, in get_version
    config = get_config().split()
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2023-10-25 12:49:00,659:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 276, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_classification.py", line 234, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_base.py", line 824, in kneighbors
    results = ArgKmin.compute(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 289, in compute
    return ArgKmin32.compute(
  File "sklearn\metrics\_pairwise_distances_reduction\_argkmin.pyx", line 584, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\fixes.py", line 139, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 373, in _load_modules
    self._find_modules_with_enum_process_module_ex()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 485, in _find_modules_with_enum_process_module_ex
    self._make_module_from_path(filepath)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 646, in get_version
    config = get_config().split()
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2023-10-25 12:49:00,690:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 276, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_classification.py", line 234, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_base.py", line 824, in kneighbors
    results = ArgKmin.compute(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 289, in compute
    return ArgKmin32.compute(
  File "sklearn\metrics\_pairwise_distances_reduction\_argkmin.pyx", line 584, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\fixes.py", line 139, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 373, in _load_modules
    self._find_modules_with_enum_process_module_ex()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 485, in _find_modules_with_enum_process_module_ex
    self._make_module_from_path(filepath)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 646, in get_version
    config = get_config().split()
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2023-10-25 12:49:01,560:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 276, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_classification.py", line 234, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_base.py", line 824, in kneighbors
    results = ArgKmin.compute(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 289, in compute
    return ArgKmin32.compute(
  File "sklearn\metrics\_pairwise_distances_reduction\_argkmin.pyx", line 584, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\fixes.py", line 139, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 373, in _load_modules
    self._find_modules_with_enum_process_module_ex()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 485, in _find_modules_with_enum_process_module_ex
    self._make_module_from_path(filepath)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 646, in get_version
    config = get_config().split()
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2023-10-25 12:49:01,586:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 276, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_classification.py", line 234, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_base.py", line 824, in kneighbors
    results = ArgKmin.compute(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 289, in compute
    return ArgKmin32.compute(
  File "sklearn\metrics\_pairwise_distances_reduction\_argkmin.pyx", line 584, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\fixes.py", line 139, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 373, in _load_modules
    self._find_modules_with_enum_process_module_ex()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 485, in _find_modules_with_enum_process_module_ex
    self._make_module_from_path(filepath)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 646, in get_version
    config = get_config().split()
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2023-10-25 12:49:01,592:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 276, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_classification.py", line 234, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_base.py", line 824, in kneighbors
    results = ArgKmin.compute(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 289, in compute
    return ArgKmin32.compute(
  File "sklearn\metrics\_pairwise_distances_reduction\_argkmin.pyx", line 584, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\fixes.py", line 139, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 373, in _load_modules
    self._find_modules_with_enum_process_module_ex()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 485, in _find_modules_with_enum_process_module_ex
    self._make_module_from_path(filepath)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 646, in get_version
    config = get_config().split()
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2023-10-25 12:49:01,623:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 276, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_classification.py", line 234, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_base.py", line 824, in kneighbors
    results = ArgKmin.compute(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 289, in compute
    return ArgKmin32.compute(
  File "sklearn\metrics\_pairwise_distances_reduction\_argkmin.pyx", line 584, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\fixes.py", line 139, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 373, in _load_modules
    self._find_modules_with_enum_process_module_ex()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 485, in _find_modules_with_enum_process_module_ex
    self._make_module_from_path(filepath)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 646, in get_version
    config = get_config().split()
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2023-10-25 12:49:04,682:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_classification.py", line 283, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_base.py", line 824, in kneighbors
    results = ArgKmin.compute(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 289, in compute
    return ArgKmin32.compute(
  File "sklearn\metrics\_pairwise_distances_reduction\_argkmin.pyx", line 584, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\fixes.py", line 139, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 373, in _load_modules
    self._find_modules_with_enum_process_module_ex()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 485, in _find_modules_with_enum_process_module_ex
    self._make_module_from_path(filepath)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 646, in get_version
    config = get_config().split()
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2023-10-25 12:49:04,901:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_classification.py", line 283, in predict_proba
    neigh_ind = self.kneighbors(X, return_distance=False)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_base.py", line 824, in kneighbors
    results = ArgKmin.compute(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 289, in compute
    return ArgKmin32.compute(
  File "sklearn\metrics\_pairwise_distances_reduction\_argkmin.pyx", line 584, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\fixes.py", line 139, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 373, in _load_modules
    self._find_modules_with_enum_process_module_ex()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 485, in _find_modules_with_enum_process_module_ex
    self._make_module_from_path(filepath)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 646, in get_version
    config = get_config().split()
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2023-10-25 12:49:06,888:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 276, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_classification.py", line 234, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_base.py", line 824, in kneighbors
    results = ArgKmin.compute(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 289, in compute
    return ArgKmin32.compute(
  File "sklearn\metrics\_pairwise_distances_reduction\_argkmin.pyx", line 584, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\fixes.py", line 139, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 373, in _load_modules
    self._find_modules_with_enum_process_module_ex()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 485, in _find_modules_with_enum_process_module_ex
    self._make_module_from_path(filepath)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 646, in get_version
    config = get_config().split()
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2023-10-25 12:49:07,045:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\model_selection\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 115, in __call__
    score = scorer._score(cached_call, estimator, *args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 276, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_classification.py", line 234, in predict
    neigh_ind = self.kneighbors(X, return_distance=False)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\neighbors\_base.py", line 824, in kneighbors
    results = ArgKmin.compute(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 289, in compute
    return ArgKmin32.compute(
  File "sklearn\metrics\_pairwise_distances_reduction\_argkmin.pyx", line 584, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\fixes.py", line 139, in threadpool_limits
    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 171, in __init__
    self._original_info = self._set_threadpool_limits()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 268, in _set_threadpool_limits
    modules = _ThreadpoolInfo(prefixes=self._prefixes,
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 340, in __init__
    self._load_modules()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 373, in _load_modules
    self._find_modules_with_enum_process_module_ex()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 485, in _find_modules_with_enum_process_module_ex
    self._make_module_from_path(filepath)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 515, in _make_module_from_path
    module = module_class(filepath, prefix, user_api, internal_api)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 606, in __init__
    self.version = self.get_version()
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\threadpoolctl.py", line 646, in get_version
    config = get_config().split()
AttributeError: 'NoneType' object has no attribute 'split'

  warnings.warn(

2023-10-25 12:49:07,320:INFO:Calculating mean and std
2023-10-25 12:49:07,320:INFO:Creating metrics dataframe
2023-10-25 12:49:07,329:INFO:Uploading results into container
2023-10-25 12:49:07,329:INFO:Uploading model into container now
2023-10-25 12:49:07,329:INFO:_master_model_container: 3
2023-10-25 12:49:07,329:INFO:_display_container: 2
2023-10-25 12:49:07,329:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-10-25 12:49:07,329:INFO:create_model() successfully completed......................................
2023-10-25 12:49:07,474:ERROR:create_model() for KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform') raised an exception or returned all 0.0:
2023-10-25 12:49:07,474:ERROR:Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 798, in compare_models
    assert (
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 814, in compare_models
    assert (
AssertionError

2023-10-25 12:49:07,474:INFO:Initializing Naive Bayes
2023-10-25 12:49:07,474:INFO:Total runtime is 3.0170021533966063 minutes
2023-10-25 12:49:07,487:INFO:SubProcess create_model() called ==================================
2023-10-25 12:49:07,487:INFO:Initializing create_model()
2023-10-25 12:49:07,487:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BDB7F9B9A0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002BDB7F66C70>, model_only=True, return_train_score=False, kwargs={})
2023-10-25 12:49:07,487:INFO:Checking exceptions
2023-10-25 12:49:07,487:INFO:Importing libraries
2023-10-25 12:49:07,487:INFO:Copying training dataset
2023-10-25 12:49:09,530:INFO:Defining folds
2023-10-25 12:49:09,530:INFO:Declaring metric variables
2023-10-25 12:49:09,546:INFO:Importing untrained model
2023-10-25 12:49:09,546:INFO:Naive Bayes Imported successfully
2023-10-25 12:49:09,576:INFO:Starting cross validation
2023-10-25 12:49:09,588:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-25 12:49:33,794:INFO:Calculating mean and std
2023-10-25 12:49:33,796:INFO:Creating metrics dataframe
2023-10-25 12:49:33,803:INFO:Uploading results into container
2023-10-25 12:49:33,804:INFO:Uploading model into container now
2023-10-25 12:49:33,805:INFO:_master_model_container: 4
2023-10-25 12:49:33,805:INFO:_display_container: 2
2023-10-25 12:49:33,806:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-10-25 12:49:33,806:INFO:create_model() successfully completed......................................
2023-10-25 12:49:33,971:INFO:SubProcess create_model() end ==================================
2023-10-25 12:49:33,971:INFO:Creating metrics dataframe
2023-10-25 12:49:33,993:INFO:Initializing Decision Tree Classifier
2023-10-25 12:49:33,993:INFO:Total runtime is 3.45898695786794 minutes
2023-10-25 12:49:34,001:INFO:SubProcess create_model() called ==================================
2023-10-25 12:49:34,001:INFO:Initializing create_model()
2023-10-25 12:49:34,001:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BDB7F9B9A0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002BDB7F66C70>, model_only=True, return_train_score=False, kwargs={})
2023-10-25 12:49:34,001:INFO:Checking exceptions
2023-10-25 12:49:34,001:INFO:Importing libraries
2023-10-25 12:49:34,001:INFO:Copying training dataset
2023-10-25 12:49:36,234:INFO:Defining folds
2023-10-25 12:49:36,234:INFO:Declaring metric variables
2023-10-25 12:49:36,241:INFO:Importing untrained model
2023-10-25 12:49:36,250:INFO:Decision Tree Classifier Imported successfully
2023-10-25 12:49:36,265:INFO:Starting cross validation
2023-10-25 12:49:36,285:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-25 12:52:52,289:INFO:Calculating mean and std
2023-10-25 12:52:52,289:INFO:Creating metrics dataframe
2023-10-25 12:52:52,300:INFO:Uploading results into container
2023-10-25 12:52:52,300:INFO:Uploading model into container now
2023-10-25 12:52:52,304:INFO:_master_model_container: 5
2023-10-25 12:52:52,304:INFO:_display_container: 2
2023-10-25 12:52:52,305:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-10-25 12:52:52,305:INFO:create_model() successfully completed......................................
2023-10-25 12:52:52,452:INFO:SubProcess create_model() end ==================================
2023-10-25 12:52:52,452:INFO:Creating metrics dataframe
2023-10-25 12:52:52,467:INFO:Initializing SVM - Linear Kernel
2023-10-25 12:52:52,467:INFO:Total runtime is 6.766880317529042 minutes
2023-10-25 12:52:52,474:INFO:SubProcess create_model() called ==================================
2023-10-25 12:52:52,474:INFO:Initializing create_model()
2023-10-25 12:52:52,478:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BDB7F9B9A0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002BDB7F66C70>, model_only=True, return_train_score=False, kwargs={})
2023-10-25 12:52:52,478:INFO:Checking exceptions
2023-10-25 12:52:52,478:INFO:Importing libraries
2023-10-25 12:52:52,478:INFO:Copying training dataset
2023-10-25 12:52:54,056:INFO:Defining folds
2023-10-25 12:52:54,056:INFO:Declaring metric variables
2023-10-25 12:52:54,061:INFO:Importing untrained model
2023-10-25 12:52:54,068:INFO:SVM - Linear Kernel Imported successfully
2023-10-25 12:52:54,077:INFO:Starting cross validation
2023-10-25 12:52:54,090:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-25 12:53:25,748:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-10-25 12:53:26,750:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-10-25 12:53:28,098:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-10-25 12:53:29,991:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-10-25 12:53:30,527:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-10-25 12:53:31,890:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-10-25 12:53:33,589:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-10-25 12:53:34,159:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-10-25 12:53:41,197:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-10-25 12:53:41,466:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-10-25 12:53:41,833:INFO:Calculating mean and std
2023-10-25 12:53:41,863:INFO:Creating metrics dataframe
2023-10-25 12:53:41,913:INFO:Uploading results into container
2023-10-25 12:53:41,920:INFO:Uploading model into container now
2023-10-25 12:53:41,923:INFO:_master_model_container: 6
2023-10-25 12:53:41,924:INFO:_display_container: 2
2023-10-25 12:53:41,929:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-10-25 12:53:41,931:INFO:create_model() successfully completed......................................
2023-10-25 12:53:42,333:INFO:SubProcess create_model() end ==================================
2023-10-25 12:53:42,333:INFO:Creating metrics dataframe
2023-10-25 12:53:42,366:INFO:Initializing Ridge Classifier
2023-10-25 12:53:42,366:INFO:Total runtime is 7.598532978693643 minutes
2023-10-25 12:53:42,384:INFO:SubProcess create_model() called ==================================
2023-10-25 12:53:42,384:INFO:Initializing create_model()
2023-10-25 12:53:42,384:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BDB7F9B9A0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002BDB7F66C70>, model_only=True, return_train_score=False, kwargs={})
2023-10-25 12:53:42,384:INFO:Checking exceptions
2023-10-25 12:53:42,384:INFO:Importing libraries
2023-10-25 12:53:42,384:INFO:Copying training dataset
2023-10-25 12:53:44,132:INFO:Defining folds
2023-10-25 12:53:44,132:INFO:Declaring metric variables
2023-10-25 12:53:44,135:INFO:Importing untrained model
2023-10-25 12:53:44,144:INFO:Ridge Classifier Imported successfully
2023-10-25 12:53:44,151:INFO:Starting cross validation
2023-10-25 12:53:44,169:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-25 12:54:15,487:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-10-25 12:54:15,518:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-10-25 12:54:15,571:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-10-25 12:54:15,892:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-10-25 12:54:16,486:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-10-25 12:54:16,507:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-10-25 12:54:16,739:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-10-25 12:54:17,196:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-10-25 12:54:27,709:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-10-25 12:54:27,808:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-10-25 12:54:28,128:INFO:Calculating mean and std
2023-10-25 12:54:28,128:INFO:Creating metrics dataframe
2023-10-25 12:54:28,128:INFO:Uploading results into container
2023-10-25 12:54:28,128:INFO:Uploading model into container now
2023-10-25 12:54:28,128:INFO:_master_model_container: 7
2023-10-25 12:54:28,128:INFO:_display_container: 2
2023-10-25 12:54:28,138:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-10-25 12:54:28,138:INFO:create_model() successfully completed......................................
2023-10-25 12:54:28,295:INFO:SubProcess create_model() end ==================================
2023-10-25 12:54:28,295:INFO:Creating metrics dataframe
2023-10-25 12:54:28,329:INFO:Initializing Random Forest Classifier
2023-10-25 12:54:28,329:INFO:Total runtime is 8.364581882953642 minutes
2023-10-25 12:54:28,335:INFO:SubProcess create_model() called ==================================
2023-10-25 12:54:28,335:INFO:Initializing create_model()
2023-10-25 12:54:28,335:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BDB7F9B9A0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002BDB7F66C70>, model_only=True, return_train_score=False, kwargs={})
2023-10-25 12:54:28,335:INFO:Checking exceptions
2023-10-25 12:54:28,335:INFO:Importing libraries
2023-10-25 12:54:28,336:INFO:Copying training dataset
2023-10-25 12:54:30,110:INFO:Defining folds
2023-10-25 12:54:30,110:INFO:Declaring metric variables
2023-10-25 12:54:30,110:INFO:Importing untrained model
2023-10-25 12:54:30,129:INFO:Random Forest Classifier Imported successfully
2023-10-25 12:54:30,137:INFO:Starting cross validation
2023-10-25 12:54:30,154:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-25 12:56:35,089:INFO:Calculating mean and std
2023-10-25 12:56:35,094:INFO:Creating metrics dataframe
2023-10-25 12:56:35,100:INFO:Uploading results into container
2023-10-25 12:56:35,101:INFO:Uploading model into container now
2023-10-25 12:56:35,102:INFO:_master_model_container: 8
2023-10-25 12:56:35,102:INFO:_display_container: 2
2023-10-25 12:56:35,103:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-10-25 12:56:35,104:INFO:create_model() successfully completed......................................
2023-10-25 12:56:35,289:INFO:SubProcess create_model() end ==================================
2023-10-25 12:56:35,289:INFO:Creating metrics dataframe
2023-10-25 12:56:35,305:INFO:Initializing Quadratic Discriminant Analysis
2023-10-25 12:56:35,305:INFO:Total runtime is 10.48084759712219 minutes
2023-10-25 12:56:35,305:INFO:SubProcess create_model() called ==================================
2023-10-25 12:56:35,320:INFO:Initializing create_model()
2023-10-25 12:56:35,320:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BDB7F9B9A0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002BDB7F66C70>, model_only=True, return_train_score=False, kwargs={})
2023-10-25 12:56:35,320:INFO:Checking exceptions
2023-10-25 12:56:35,321:INFO:Importing libraries
2023-10-25 12:56:35,321:INFO:Copying training dataset
2023-10-25 12:56:37,525:INFO:Defining folds
2023-10-25 12:56:37,525:INFO:Declaring metric variables
2023-10-25 12:56:37,547:INFO:Importing untrained model
2023-10-25 12:56:37,565:INFO:Quadratic Discriminant Analysis Imported successfully
2023-10-25 12:56:37,585:INFO:Starting cross validation
2023-10-25 12:56:37,608:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-25 12:56:47,141:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-10-25 12:56:47,239:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-10-25 12:56:47,320:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-10-25 12:56:56,829:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-10-25 12:59:44,996:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-10-25 12:59:45,366:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-10-25 12:59:46,538:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-10-25 12:59:46,940:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-10-25 12:59:49,440:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-10-25 12:59:49,978:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-10-25 12:59:50,221:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-10-25 12:59:51,085:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-10-25 12:59:51,725:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-10-25 12:59:51,744:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-10-25 12:59:52,053:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-10-25 12:59:52,227:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-10-25 12:59:54,391:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-10-25 12:59:54,503:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-10-25 12:59:54,544:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-10-25 12:59:55,880:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-10-25 12:59:55,921:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-10-25 12:59:55,945:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-10-25 12:59:56,063:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-10-25 12:59:56,519:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-10-25 12:59:56,766:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-10-25 12:59:58,887:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-10-25 12:59:59,139:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-10-25 12:59:59,603:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-10-25 12:59:59,628:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-10-25 12:59:59,652:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-10-25 13:00:02,122:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-10-25 13:00:02,501:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-10-25 13:00:02,709:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-10-25 13:00:05,604:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-10-25 13:00:05,634:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-10-25 13:00:05,661:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-10-25 13:00:45,290:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-10-25 13:00:52,130:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-10-25 13:00:54,941:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-10-25 13:00:56,926:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-10-25 13:02:18,837:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\model_selection\_validation.py:378: FitFailedWarning: 
2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\pipeline.py", line 267, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\joblib\memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\discriminant_analysis.py", line 923, in fit
    _, S, Vt = np.linalg.svd(Xgc, full_matrices=False)
  File "<__array_function__ internals>", line 180, in svd
  File "c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\numpy\linalg\linalg.py", line 1657, in svd
    u, s, vh = gufunc(a, signature=signature, extobj=extobj)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 369. MiB for an array with shape (2735, 17682) and data type float64

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-10-25 13:02:18,848:INFO:Calculating mean and std
2023-10-25 13:02:18,869:INFO:Creating metrics dataframe
2023-10-25 13:02:18,908:INFO:Uploading results into container
2023-10-25 13:02:18,910:INFO:Uploading model into container now
2023-10-25 13:02:18,912:INFO:_master_model_container: 9
2023-10-25 13:02:18,912:INFO:_display_container: 2
2023-10-25 13:02:18,913:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-10-25 13:02:18,913:INFO:create_model() successfully completed......................................
2023-10-25 13:02:19,134:INFO:SubProcess create_model() end ==================================
2023-10-25 13:02:19,134:INFO:Creating metrics dataframe
2023-10-25 13:02:19,151:INFO:Initializing Ada Boost Classifier
2023-10-25 13:02:19,152:INFO:Total runtime is 16.21163490215937 minutes
2023-10-25 13:02:19,156:INFO:SubProcess create_model() called ==================================
2023-10-25 13:02:19,157:INFO:Initializing create_model()
2023-10-25 13:02:19,157:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BDB7F9B9A0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002BDB7F66C70>, model_only=True, return_train_score=False, kwargs={})
2023-10-25 13:02:19,157:INFO:Checking exceptions
2023-10-25 13:02:19,158:INFO:Importing libraries
2023-10-25 13:02:19,158:INFO:Copying training dataset
2023-10-25 13:02:20,650:INFO:Defining folds
2023-10-25 13:02:20,650:INFO:Declaring metric variables
2023-10-25 13:02:20,654:INFO:Importing untrained model
2023-10-25 13:02:20,660:INFO:Ada Boost Classifier Imported successfully
2023-10-25 13:02:20,667:INFO:Starting cross validation
2023-10-25 13:02:20,679:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-25 13:03:40,859:INFO:Calculating mean and std
2023-10-25 13:03:40,861:INFO:Creating metrics dataframe
2023-10-25 13:03:40,867:INFO:Uploading results into container
2023-10-25 13:03:40,870:INFO:Uploading model into container now
2023-10-25 13:03:40,872:INFO:_master_model_container: 10
2023-10-25 13:03:40,872:INFO:_display_container: 2
2023-10-25 13:03:40,874:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-10-25 13:03:40,874:INFO:create_model() successfully completed......................................
2023-10-25 13:03:41,036:INFO:SubProcess create_model() end ==================================
2023-10-25 13:03:41,036:INFO:Creating metrics dataframe
2023-10-25 13:03:41,050:INFO:Initializing Gradient Boosting Classifier
2023-10-25 13:03:41,050:INFO:Total runtime is 17.576592417558032 minutes
2023-10-25 13:03:41,054:INFO:SubProcess create_model() called ==================================
2023-10-25 13:03:41,055:INFO:Initializing create_model()
2023-10-25 13:03:41,055:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BDB7F9B9A0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002BDB7F66C70>, model_only=True, return_train_score=False, kwargs={})
2023-10-25 13:03:41,055:INFO:Checking exceptions
2023-10-25 13:03:41,055:INFO:Importing libraries
2023-10-25 13:03:41,055:INFO:Copying training dataset
2023-10-25 13:03:42,414:INFO:Defining folds
2023-10-25 13:03:42,414:INFO:Declaring metric variables
2023-10-25 13:03:42,422:INFO:Importing untrained model
2023-10-25 13:03:42,427:INFO:Gradient Boosting Classifier Imported successfully
2023-10-25 13:03:42,435:INFO:Starting cross validation
2023-10-25 13:03:42,446:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-25 14:29:47,156:INFO:Calculating mean and std
2023-10-25 14:29:47,156:INFO:Creating metrics dataframe
2023-10-25 14:29:47,156:INFO:Uploading results into container
2023-10-25 14:29:47,156:INFO:Uploading model into container now
2023-10-25 14:29:47,156:INFO:_master_model_container: 11
2023-10-25 14:29:47,156:INFO:_display_container: 2
2023-10-25 14:29:47,172:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-10-25 14:29:47,172:INFO:create_model() successfully completed......................................
2023-10-25 14:29:47,305:INFO:SubProcess create_model() end ==================================
2023-10-25 14:29:47,305:INFO:Creating metrics dataframe
2023-10-25 14:29:47,327:INFO:Initializing Linear Discriminant Analysis
2023-10-25 14:29:47,327:INFO:Total runtime is 103.68121052185694 minutes
2023-10-25 14:29:47,341:INFO:SubProcess create_model() called ==================================
2023-10-25 14:29:47,341:INFO:Initializing create_model()
2023-10-25 14:29:47,341:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BDB7F9B9A0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002BDB7F66C70>, model_only=True, return_train_score=False, kwargs={})
2023-10-25 14:29:47,341:INFO:Checking exceptions
2023-10-25 14:29:47,341:INFO:Importing libraries
2023-10-25 14:29:47,341:INFO:Copying training dataset
2023-10-25 14:29:49,410:INFO:Defining folds
2023-10-25 14:29:49,410:INFO:Declaring metric variables
2023-10-25 14:29:49,431:INFO:Importing untrained model
2023-10-25 14:29:49,439:INFO:Linear Discriminant Analysis Imported successfully
2023-10-25 14:29:49,449:INFO:Starting cross validation
2023-10-25 14:29:49,464:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-25 15:35:09,604:INFO:Calculating mean and std
2023-10-25 15:35:09,772:INFO:Creating metrics dataframe
2023-10-25 15:35:10,013:INFO:Uploading results into container
2023-10-25 15:35:10,036:INFO:Uploading model into container now
2023-10-25 15:35:10,052:INFO:_master_model_container: 12
2023-10-25 15:35:10,052:INFO:_display_container: 2
2023-10-25 15:35:10,082:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-10-25 15:35:10,082:INFO:create_model() successfully completed......................................
2023-10-25 15:35:11,467:INFO:SubProcess create_model() end ==================================
2023-10-25 15:35:11,467:INFO:Creating metrics dataframe
2023-10-25 15:35:11,564:INFO:Initializing Extra Trees Classifier
2023-10-25 15:35:11,564:INFO:Total runtime is 169.0851677576701 minutes
2023-10-25 15:35:11,588:INFO:SubProcess create_model() called ==================================
2023-10-25 15:35:11,588:INFO:Initializing create_model()
2023-10-25 15:35:11,588:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BDB7F9B9A0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002BDB7F66C70>, model_only=True, return_train_score=False, kwargs={})
2023-10-25 15:35:11,588:INFO:Checking exceptions
2023-10-25 15:35:11,592:INFO:Importing libraries
2023-10-25 15:35:11,595:INFO:Copying training dataset
2023-10-25 15:35:16,422:INFO:Defining folds
2023-10-25 15:35:16,427:INFO:Declaring metric variables
2023-10-25 15:35:16,436:INFO:Importing untrained model
2023-10-25 15:35:16,452:INFO:Extra Trees Classifier Imported successfully
2023-10-25 15:35:16,476:INFO:Starting cross validation
2023-10-25 15:35:16,511:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-25 15:40:14,507:INFO:Calculating mean and std
2023-10-25 15:40:14,511:INFO:Creating metrics dataframe
2023-10-25 15:40:14,514:INFO:Uploading results into container
2023-10-25 15:40:14,521:INFO:Uploading model into container now
2023-10-25 15:40:14,523:INFO:_master_model_container: 13
2023-10-25 15:40:14,523:INFO:_display_container: 2
2023-10-25 15:40:14,524:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-10-25 15:40:14,524:INFO:create_model() successfully completed......................................
2023-10-25 15:40:14,877:INFO:SubProcess create_model() end ==================================
2023-10-25 15:40:14,877:INFO:Creating metrics dataframe
2023-10-25 15:40:14,928:INFO:Initializing Light Gradient Boosting Machine
2023-10-25 15:40:14,928:INFO:Total runtime is 174.14122585455578 minutes
2023-10-25 15:40:14,942:INFO:SubProcess create_model() called ==================================
2023-10-25 15:40:14,945:INFO:Initializing create_model()
2023-10-25 15:40:14,945:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BDB7F9B9A0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002BDB7F66C70>, model_only=True, return_train_score=False, kwargs={})
2023-10-25 15:40:14,945:INFO:Checking exceptions
2023-10-25 15:40:14,945:INFO:Importing libraries
2023-10-25 15:40:14,945:INFO:Copying training dataset
2023-10-25 15:40:19,207:INFO:Defining folds
2023-10-25 15:40:19,211:INFO:Declaring metric variables
2023-10-25 15:40:19,228:INFO:Importing untrained model
2023-10-25 15:40:19,244:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-25 15:40:19,271:INFO:Starting cross validation
2023-10-25 15:40:19,297:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-25 15:40:43,726:INFO:Calculating mean and std
2023-10-25 15:40:43,736:INFO:Creating metrics dataframe
2023-10-25 15:40:43,766:INFO:Uploading results into container
2023-10-25 15:40:43,773:INFO:Uploading model into container now
2023-10-25 15:40:43,776:INFO:_master_model_container: 14
2023-10-25 15:40:43,778:INFO:_display_container: 2
2023-10-25 15:40:43,781:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-10-25 15:40:43,781:INFO:create_model() successfully completed......................................
2023-10-25 15:40:44,061:INFO:SubProcess create_model() end ==================================
2023-10-25 15:40:44,061:INFO:Creating metrics dataframe
2023-10-25 15:40:44,114:INFO:Initializing Dummy Classifier
2023-10-25 15:40:44,114:INFO:Total runtime is 174.62766670385997 minutes
2023-10-25 15:40:44,136:INFO:SubProcess create_model() called ==================================
2023-10-25 15:40:44,136:INFO:Initializing create_model()
2023-10-25 15:40:44,141:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BDB7F9B9A0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002BDB7F66C70>, model_only=True, return_train_score=False, kwargs={})
2023-10-25 15:40:44,142:INFO:Checking exceptions
2023-10-25 15:40:44,142:INFO:Importing libraries
2023-10-25 15:40:44,142:INFO:Copying training dataset
2023-10-25 15:40:48,561:INFO:Defining folds
2023-10-25 15:40:48,561:INFO:Declaring metric variables
2023-10-25 15:40:48,581:INFO:Importing untrained model
2023-10-25 15:40:48,599:INFO:Dummy Classifier Imported successfully
2023-10-25 15:40:48,631:INFO:Starting cross validation
2023-10-25 15:40:48,673:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-25 15:40:50,233:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-10-25 15:40:50,251:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-10-25 15:40:50,264:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-10-25 15:40:50,269:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-10-25 15:40:50,284:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-10-25 15:40:50,344:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-10-25 15:40:50,354:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-10-25 15:40:50,374:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-10-25 15:40:51,276:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-10-25 15:40:51,276:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-10-25 15:40:51,687:INFO:Calculating mean and std
2023-10-25 15:40:51,718:INFO:Creating metrics dataframe
2023-10-25 15:40:51,741:INFO:Uploading results into container
2023-10-25 15:40:51,741:INFO:Uploading model into container now
2023-10-25 15:40:51,745:INFO:_master_model_container: 15
2023-10-25 15:40:51,745:INFO:_display_container: 2
2023-10-25 15:40:51,745:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-10-25 15:40:51,745:INFO:create_model() successfully completed......................................
2023-10-25 15:40:52,111:INFO:SubProcess create_model() end ==================================
2023-10-25 15:40:52,112:INFO:Creating metrics dataframe
2023-10-25 15:40:52,206:INFO:Initializing create_model()
2023-10-25 15:40:52,206:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BDB7F9B9A0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-25 15:40:52,206:INFO:Checking exceptions
2023-10-25 15:40:52,219:INFO:Importing libraries
2023-10-25 15:40:52,219:INFO:Copying training dataset
2023-10-25 15:40:56,341:INFO:Defining folds
2023-10-25 15:40:56,341:INFO:Declaring metric variables
2023-10-25 15:40:56,342:INFO:Importing untrained model
2023-10-25 15:40:56,342:INFO:Declaring custom model
2023-10-25 15:40:56,342:INFO:Logistic Regression Imported successfully
2023-10-25 15:40:56,382:INFO:Cross validation set to False
2023-10-25 15:40:56,382:INFO:Fitting Model
2023-10-25 15:41:09,142:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-10-25 15:41:09,142:INFO:create_model() successfully completed......................................
2023-10-25 15:41:09,458:INFO:Creating Dashboard logs
2023-10-25 15:41:09,464:INFO:Model: Logistic Regression
2023-10-25 15:41:09,636:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 123, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2023-10-25 15:41:10,263:INFO:Initializing predict_model()
2023-10-25 15:41:10,263:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BDB7F9B9A0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002BDBA99E3A0>)
2023-10-25 15:41:10,266:INFO:Checking exceptions
2023-10-25 15:41:10,266:INFO:Preloading libraries
2023-10-25 15:41:20,372:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\_distutils_hack\__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2023-10-25 15:41:20,696:INFO:Creating Dashboard logs
2023-10-25 15:41:20,711:INFO:Model: Extra Trees Classifier
2023-10-25 15:41:20,825:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-25 15:41:21,552:INFO:Creating Dashboard logs
2023-10-25 15:41:21,568:INFO:Model: Ridge Classifier
2023-10-25 15:41:21,721:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 123, 'solver': 'auto', 'tol': 0.0001}
2023-10-25 15:41:22,335:INFO:Creating Dashboard logs
2023-10-25 15:41:22,351:INFO:Model: Random Forest Classifier
2023-10-25 15:41:22,501:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 123, 'verbose': 0, 'warm_start': False}
2023-10-25 15:41:23,261:INFO:Creating Dashboard logs
2023-10-25 15:41:23,274:INFO:Model: SVM - Linear Kernel
2023-10-25 15:41:23,394:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 123, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-10-25 15:41:24,120:INFO:Creating Dashboard logs
2023-10-25 15:41:24,132:INFO:Model: Light Gradient Boosting Machine
2023-10-25 15:41:24,251:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-10-25 15:41:24,934:INFO:Creating Dashboard logs
2023-10-25 15:41:24,958:INFO:Model: Decision Tree Classifier
2023-10-25 15:41:25,073:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 123, 'splitter': 'best'}
2023-10-25 15:41:25,816:INFO:Creating Dashboard logs
2023-10-25 15:41:25,827:INFO:Model: Ada Boost Classifier
2023-10-25 15:41:25,964:INFO:Logged params: {'algorithm': 'SAMME.R', 'base_estimator': 'deprecated', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 123}
2023-10-25 15:41:26,547:INFO:Creating Dashboard logs
2023-10-25 15:41:26,561:INFO:Model: Gradient Boosting Classifier
2023-10-25 15:41:26,694:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 123, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-10-25 15:41:27,364:INFO:Creating Dashboard logs
2023-10-25 15:41:27,381:INFO:Model: Linear Discriminant Analysis
2023-10-25 15:41:27,501:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2023-10-25 15:41:28,136:INFO:Creating Dashboard logs
2023-10-25 15:41:28,156:INFO:Model: Naive Bayes
2023-10-25 15:41:28,267:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2023-10-25 15:41:28,881:INFO:Creating Dashboard logs
2023-10-25 15:41:28,891:INFO:Model: Dummy Classifier
2023-10-25 15:41:29,038:INFO:Logged params: {'constant': None, 'random_state': 123, 'strategy': 'prior'}
2023-10-25 15:41:29,671:INFO:Creating Dashboard logs
2023-10-25 15:41:29,681:INFO:Model: Quadratic Discriminant Analysis
2023-10-25 15:41:29,831:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2023-10-25 15:41:30,468:INFO:_master_model_container: 15
2023-10-25 15:41:30,468:INFO:_display_container: 2
2023-10-25 15:41:30,471:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-10-25 15:41:30,471:INFO:compare_models() successfully completed......................................
2023-10-25 15:41:31,136:INFO:Initializing plot_model()
2023-10-25 15:41:31,141:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BDB7F9B9A0>, system=True)
2023-10-25 15:41:31,141:INFO:Checking exceptions
2023-10-25 15:41:32,861:INFO:Preloading libraries
2023-10-25 15:41:32,894:INFO:Copying training dataset
2023-10-25 15:41:32,894:INFO:Plot type: auc
2023-10-25 15:41:42,996:INFO:Fitting Model
2023-10-25 15:41:43,012:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2023-10-25 15:41:43,012:INFO:Scoring test/hold-out set
2023-10-25 15:41:47,243:INFO:Visual Rendered Successfully
2023-10-25 15:41:47,552:INFO:plot_model() successfully completed......................................
2023-10-25 15:41:47,786:INFO:Initializing plot_model()
2023-10-25 15:41:47,786:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BDB7F9B9A0>, system=True)
2023-10-25 15:41:47,786:INFO:Checking exceptions
2023-10-25 15:41:49,342:INFO:Preloading libraries
2023-10-25 15:41:49,383:INFO:Copying training dataset
2023-10-25 15:41:49,383:INFO:Plot type: confusion_matrix
2023-10-25 15:41:59,739:INFO:Fitting Model
2023-10-25 15:41:59,739:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2023-10-25 15:41:59,741:INFO:Scoring test/hold-out set
2023-10-25 15:42:03,746:INFO:Visual Rendered Successfully
2023-10-25 15:42:04,116:INFO:plot_model() successfully completed......................................
2023-10-25 15:42:04,235:INFO:Initializing plot_model()
2023-10-25 15:42:04,235:INFO:plot_model(plot=boundary, fold=None, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002BDB7F9B9A0>, system=True)
2023-10-25 15:42:04,235:INFO:Checking exceptions
2023-10-25 15:42:05,762:INFO:Preloading libraries
2023-10-25 15:42:05,796:INFO:Copying training dataset
2023-10-25 15:42:05,796:INFO:Plot type: boundary
2023-10-25 15:42:10,624:INFO:Fitting StandardScaler()
2023-10-25 15:42:16,711:INFO:Fitting PCA()
2023-10-25 15:42:27,935:INFO:Fitting Model
2023-10-25 15:42:32,776:INFO:Visual Rendered Successfully
2023-10-25 15:42:33,044:INFO:plot_model() successfully completed......................................
2023-10-25 15:55:46,962:INFO:Initializing save_model()
2023-10-25 15:55:46,962:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=../../models/1_pycaret, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\enric\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)], verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-10-25 15:55:46,962:INFO:Adding model into prep_pipe
2023-10-25 15:55:47,387:INFO:../../models/1_pycaret.pkl saved in current working directory
2023-10-25 15:55:47,396:INFO:Pipeline(memory=Memory(location=None),
         steps=[('placeholder', None),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=123,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2023-10-25 15:55:47,396:INFO:save_model() successfully completed......................................
2023-10-25 17:01:33,379:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-25 17:01:33,379:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-25 17:01:33,379:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-25 17:01:33,379:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-26 09:36:22,576:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-26 09:36:22,578:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-26 09:36:22,578:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-26 09:36:22,578:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-26 09:47:20,036:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-10-26 10:49:25,639:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-26 10:49:25,639:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-26 10:49:25,639:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-26 10:49:25,639:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-26 10:50:27,185:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-10-26 10:53:04,640:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-26 10:53:04,640:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-26 10:53:04,640:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-26 10:53:04,640:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-26 10:53:58,954:WARNING:c:\Users\enric\.conda\envs\npl-tweets\lib\site-packages\sklearn\utils\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2023-10-26 10:56:23,640:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-26 10:56:23,641:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-26 10:56:23,641:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-26 10:56:23,641:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
